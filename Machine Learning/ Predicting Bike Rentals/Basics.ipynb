{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>Predicting Bike Rentals using Machine Learning</h1>\n",
    "\n",
    "Many American cities have communal bike sharing stations where you can rent bicycles by the hour or day. Washington, D.C. is one of these cities. The District collects detailed data on the number of bicycles people rent by the hour and day.\n",
    "\n",
    "Hadi Fanaee-T at the University of Porto compiled this data into a CSV file, which I'll be working with in this project. The file contains 17380 rows, with each row representing the number of bike rentals for a single hour of a single day. You can download the data from the University of California, Irvine's <a href=\"http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset\">website.</a>\n",
    "\n",
    "Here are the descriptions for the relevant columns:\n",
    "\n",
    "* instant - A unique sequential ID number for each row\n",
    "* dteday - The date of the rentals\n",
    "* season - The season in which the rentals occurred\n",
    "* yr - The year the rentals occurred\n",
    "* mnth - The month the rentals occurred\n",
    "* hr - The hour the rentals occurred\n",
    "* holiday - Whether or not the day was a holiday\n",
    "* weekday - Whether or not the day was a weekday\n",
    "* workingday - Whether or not the day was a working day\n",
    "* weathersit - The weather (as a categorical variable)\n",
    "* temp - The temperature, on a 0-1 scale\n",
    "* atemp - The adjusted temperature\n",
    "* hum - The humidity, on a 0-1 scale\n",
    "* windspeed - The wind speed, on a 0-1 scale\n",
    "* casual - The number of casual riders (people who hadn't previously signed up with the bike sharing program)\n",
    "* registered - The number of registered riders (people who had already signed up)\n",
    "* cnt - The total number of bike rentals (casual + registered)\n",
    "\n",
    "In this project, I'll try to predict the total number of bikes people rented in a given hour. I'll predict the cnt column using all of the other columns, except for casual and registered. To accomplish this, I'll create a few different machine learning models and evaluate their performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import dependences\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_rentals = pd.read_csv(\"bike_rental_hour.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_rentals.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Data columns (total 17 columns):\n",
      "instant       17379 non-null int64\n",
      "dteday        17379 non-null object\n",
      "season        17379 non-null int64\n",
      "yr            17379 non-null int64\n",
      "mnth          17379 non-null int64\n",
      "hr            17379 non-null int64\n",
      "holiday       17379 non-null int64\n",
      "weekday       17379 non-null int64\n",
      "workingday    17379 non-null int64\n",
      "weathersit    17379 non-null int64\n",
      "temp          17379 non-null float64\n",
      "atemp         17379 non-null float64\n",
      "hum           17379 non-null float64\n",
      "windspeed     17379 non-null float64\n",
      "casual        17379 non-null int64\n",
      "registered    17379 non-null int64\n",
      "cnt           17379 non-null int64\n",
      "dtypes: float64(4), int64(12), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "bike_rentals.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am in luck, as most the columns are numerical, and will not require a change in datatype.\n",
    "Lets look at the distribution of bike rentals by making a histogram of the cnt column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa0305e2cf8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa0305f5128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bike_rentals[\"cnt\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make a correlation matrix, which I can then use to observe the correlation between each of my feature columns, and my target, cnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_matrix = bike_rentals.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       0.278379\n",
       "season        0.178056\n",
       "yr            0.250495\n",
       "mnth          0.120638\n",
       "hr            0.394071\n",
       "holiday      -0.030927\n",
       "weekday       0.026900\n",
       "workingday    0.030284\n",
       "weathersit   -0.142426\n",
       "temp          0.404772\n",
       "atemp         0.400929\n",
       "hum          -0.322911\n",
       "windspeed     0.093234\n",
       "casual        0.694564\n",
       "registered    0.972151\n",
       "cnt           1.000000\n",
       "Name: cnt, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix['cnt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can often be helpful to calculate features before applying machine learning models. Features can enhance the accuracy of models by introducing new information, or distilling existing information.\n",
    "\n",
    "For example, the hr column in bike_rentals contains the hours during which bikes are rented, from 1 to 24. A machine will treat each hour differently, without understanding that certain hours are related. I can introduce some order into the process by creating a new column with labels for morning, afternoon, evening, and night. This will bundle similar times together, enabling the model to make better decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assign_label(hr):\n",
    "    \"\"\"Assign labels as follows:\n",
    "    1: Morning\n",
    "    2: Afternoon\n",
    "    3: Evening\n",
    "    4: Night\"\"\"\n",
    "    if hr >=6 and hr <12:\n",
    "        return 1\n",
    "    elif hr >=12 and hr <18:\n",
    "        return 2\n",
    "    elif hr >=18 and hr <24:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bike_rentals[\"time_label\"] = bike_rentals['hr'].apply(assign_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I can begin applying machine learning algorithms, I'll need to split the data into training and testing sets. This will enable me to train an algorithm using the training set, and evaluate its accuracy on the testing set. If I train an algorithm on the training data, then evaluate its performance on the same data, I can get an unrealistically low error value, due to overfitting.\n",
    "\n",
    "I also need to chose an error metric by which I will evaluate my model with. The prediction I am trying to make here is a problem of regression rather than classification. My target column contains continuous data and I am trying to predict a value accuarately, rather than trying to categorise based on my features. I will therefore use Mean Squared Error which will provide me with the magnitude of error from my model. I can also take the root of this value to convert the units of the error value back to the units of my original target column (quantity of bikes rented)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = bike_rentals.sample(frac=0.8, random_state=1)\n",
    "test = bike_rentals.loc[~bike_rentals.index.isin(train.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I've done some exploration and manipulation, I am ready to apply linear regression to the data. Linear regression will probably work fairly well on this data, given that some of the columns are highly correlated with cnt.\n",
    "\n",
    "Linear regression works best when predictors are linearly correlated to the target and also independent -- in other words, they don't change meaning when we combine them with each other. The good thing about linear regression is that it's fairly resistant to overfitting because it's straightforward. It also can be prone to underfitting the data, however, and not building a powerful enough model. This means that linear regression usually isn't the most accurate option.\n",
    "\n",
    "I'll need to ignore the casual and registered columns because cnt is derived from them. If I'mtrying to predict the number of people who rent bikes in a given hour (cnt), it doesn't make sense that I would already know casual or registered, because those numbers are added together to get cnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = bike_rentals.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_to_remove = ['dteday', 'casual', 'registered', 'cnt']\n",
    "for c in columns_to_remove:\n",
    "    features.remove(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'cnt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130.583784871\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(train[features], train[target])\n",
    "predictions = model.predict(test[features])\n",
    "mse = mean_squared_error(test[target],predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error is very high. This might be a result of large outliers, for example there are a few very high rental counts, which skew the data. Large errors are penalised more with mean squared error, which leads to a higher overall error, so outliers have a heavy influence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I shall try applying instead a decision tree to this problem. Then I shall compare the performance of both. \n",
    "Decision trees tend to predict outcomes much more reliably than linear regression models. Because a decision tree is a fairly complex model, it also tends to overfit, particularly when we don't tweak parameters like maximum depth and minimum number of samples per leaf. Decision trees are also prone to instability -- small changes in the input data can result in a very different output model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.5819474092\n"
     ]
    }
   ],
   "source": [
    "def create_df_model(min_samples_leaf=1):    \n",
    "    dt_model = DecisionTreeRegressor(min_samples_leaf=min_samples_leaf)\n",
    "    dt_model.fit(train[features],train[target])\n",
    "    dt_predictions = dt_model.predict(test[features])\n",
    "    dt_mse = mean_squared_error(test[target], dt_predictions)\n",
    "    dt_rmse = np.sqrt(dt_mse)\n",
    "    print(dt_rmse)\n",
    "create_df_model(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already we can see a significant reduction in error. I shall now experiment with parameters to try and reduce any overfitting. The 'min_samples_leaf' parameter defines the minimum number of samples to define a 'leaf'. By default this value is 1, so I shall try changing it and seeing the effect on the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.1425034624\n"
     ]
    }
   ],
   "source": [
    "#min_samples_leaf = 2\n",
    "create_df_model(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.3147086686\n"
     ]
    }
   ],
   "source": [
    "#min_samples_leaf = 5\n",
    "create_df_model(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.0097663572\n"
     ]
    }
   ],
   "source": [
    "#min_samples_leaf = 10\n",
    "create_df_model(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, increasing 'min_samples_leaf' has diminishing returns, this is because as the complexity of the model decreases, the model becomes less likely to overfit, but more likely to hold bias.\n",
    "\n",
    "I will now apply the random forest algorithm, which improves on the decision tree algorithm. Random forests tend to be much more accurate than simple models like linear regression. Due to the way random forests are constructed, they tend to overfit much less than decision trees. Random forests can still be prone to overfitting, though, so it's important to tune parameters like maximum depth and minimum samples per leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_rf_model(min_samples_leaf = 1):\n",
    "    rf_model = RandomForestRegressor(min_samples_leaf=min_samples_leaf)\n",
    "    rf_model.fit(train[features],train[target])\n",
    "    rf_predictions = rf_model.predict(test[features])\n",
    "    rf_mse = mean_squared_error(test[target], rf_predictions)\n",
    "    rf_rmse = np.sqrt(rf_mse)\n",
    "    print(rf_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.939638312\n"
     ]
    }
   ],
   "source": [
    "create_rf_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.6971780704\n"
     ]
    }
   ],
   "source": [
    "create_rf_model(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that the random forest model performs better, with a reduction in RMSE. The random forest model reduces overfitting by sampling predictions from multiple decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
